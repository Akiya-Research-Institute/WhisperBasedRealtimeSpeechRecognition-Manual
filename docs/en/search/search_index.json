{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"What is WhisperRealtime? Whisper-based Real-time Speech Recognition , or WhisperRealtime for short, is an Unreal Engine plugin for real-time speech-to-text transcription and translation with multi-language support, based on OpenAI's Whisper model. Just add one component to your BP and you are ready to use it. No python or any separated servers needed. Demo project available on GitHub .","title":"What is WhisperRealtime?"},{"location":"#what-is-whisperrealtime","text":"Whisper-based Real-time Speech Recognition , or WhisperRealtime for short, is an Unreal Engine plugin for real-time speech-to-text transcription and translation with multi-language support, based on OpenAI's Whisper model. Just add one component to your BP and you are ready to use it. No python or any separated servers needed. Demo project available on GitHub .","title":"What is WhisperRealtime?"},{"location":"changelog/","text":"Changelog v1.0 (Dec ??, 2022) First release.","title":"Changelog"},{"location":"changelog/#changelog","text":"","title":"Changelog"},{"location":"changelog/#v10-dec-2022","text":"First release.","title":"v1.0 (Dec ??, 2022)"},{"location":"demo-project-overview/","text":"Realtime transcription demo Whisper-based Real-time Speech Recognition , or WhisperRealtime for short, is an Unreal Engine plugin for real-time speech-to-text transcription and translation with multi-language support, based on OpenAI's Whisper model. Demo project is available on GitHub . System Requirements Windows 10 64bit Unreal Engine 5.1.0 WhisperRealtime plugin v1.0.0 or above Microphone connected to your PC If you want to run with GPU, CUDA: 11.6 cuDNN: 8.5.0.96 How to use the demo Clone the repository: git clone git@github.com:Akiya-Research-Institute/WhisperRealtime-Demo.git Open WhisperRealtime-Demo/WhisperRealtimeDemo.uproject Click Play on UE editor. Say something to your microphone. Options Execution device : Whether to use CPU or GPU. Model Size : The larger the model, the higher the accuracy and the greater the CPU/GPU/memory usage. Language : The language to be spoken. Translate to English : If you just want to transcribe speech to text in the language specified above, select No . If you want to translate it to English, select Yes . Stop transcription : Stops the transcription process.","title":"Realtime transcription demo"},{"location":"demo-project-overview/#realtime-transcription-demo","text":"Whisper-based Real-time Speech Recognition , or WhisperRealtime for short, is an Unreal Engine plugin for real-time speech-to-text transcription and translation with multi-language support, based on OpenAI's Whisper model. Demo project is available on GitHub .","title":"Realtime transcription demo"},{"location":"demo-project-overview/#system-requirements","text":"Windows 10 64bit Unreal Engine 5.1.0 WhisperRealtime plugin v1.0.0 or above Microphone connected to your PC If you want to run with GPU, CUDA: 11.6 cuDNN: 8.5.0.96","title":"System Requirements"},{"location":"demo-project-overview/#how-to-use-the-demo","text":"Clone the repository: git clone git@github.com:Akiya-Research-Institute/WhisperRealtime-Demo.git Open WhisperRealtime-Demo/WhisperRealtimeDemo.uproject Click Play on UE editor. Say something to your microphone.","title":"How to use the demo"},{"location":"demo-project-overview/#options","text":"Execution device : Whether to use CPU or GPU. Model Size : The larger the model, the higher the accuracy and the greater the CPU/GPU/memory usage. Language : The language to be spoken. Translate to English : If you just want to transcribe speech to text in the language specified above, select No . If you want to translate it to English, select Yes . Stop transcription : Stops the transcription process.","title":"Options"},{"location":"faq/","text":"FAQ UE crashes when GPU_CUDA is selected Please confirm you have installed CUDA and cuDNN correctly.","title":"FAQ"},{"location":"faq/#faq","text":"","title":"FAQ"},{"location":"faq/#ue-crashes-when-gpu_cuda-is-selected","text":"Please confirm you have installed CUDA and cuDNN correctly.","title":"UE crashes when GPU_CUDA is selected"},{"location":"how-to-use/","text":"How to use Note There is an example BP at Plugins > WhisperRealtime > Sample > BP > BP_WhisperTranscriptRealtime . You can test it in sample map located at Plugins > WhisperRealtime > Sample > Map > test_transcript . Create an actor blueprint. Add Whisper Transcript Realtime component. Set the default settings: Specify Model Size . The larger the model, higher the accuracy and the CPU/GPU/memory usage. Specify Execution device , whether to use CPU or GPU. Specify GPU Device ID if you use GPU and you have multiple GPUs in your PC. Specify Language spoken . Specify Do Translate to English . If you just want to transcribe speech to text in the language specified above, leave unchecked. Specify Prohibited Phrases if you want to suppress certain phrases. Note that this feature simply removes the specified phrases from the result. If you specify a short phrase, for example at , the phrase will be removed from all words (e.g. that becomes th ). Get results from On Speaking event and On Spoken event. On Speaking event gives intermidiate result while the user is still speaking. On Spoken event gives the final result after the user stops speaking. To stop transcription or translation, call Stop Transcription function of Whisper Transcript Realtime component. To restart transcription or translation, call Restart Transcription function of Whisper Transcript Realtime component. To change settings, call Change Setting function of Whisper Transcript Realtime component.","title":"How to use"},{"location":"how-to-use/#how-to-use","text":"Note There is an example BP at Plugins > WhisperRealtime > Sample > BP > BP_WhisperTranscriptRealtime . You can test it in sample map located at Plugins > WhisperRealtime > Sample > Map > test_transcript . Create an actor blueprint. Add Whisper Transcript Realtime component. Set the default settings: Specify Model Size . The larger the model, higher the accuracy and the CPU/GPU/memory usage. Specify Execution device , whether to use CPU or GPU. Specify GPU Device ID if you use GPU and you have multiple GPUs in your PC. Specify Language spoken . Specify Do Translate to English . If you just want to transcribe speech to text in the language specified above, leave unchecked. Specify Prohibited Phrases if you want to suppress certain phrases. Note that this feature simply removes the specified phrases from the result. If you specify a short phrase, for example at , the phrase will be removed from all words (e.g. that becomes th ). Get results from On Speaking event and On Spoken event. On Speaking event gives intermidiate result while the user is still speaking. On Spoken event gives the final result after the user stops speaking. To stop transcription or translation, call Stop Transcription function of Whisper Transcript Realtime component. To restart transcription or translation, call Restart Transcription function of Whisper Transcript Realtime component. To change settings, call Change Setting function of Whisper Transcript Realtime component.","title":"How to use"},{"location":"install/","text":"Installation Purchase at UE Marketplace and install it. Create an Unreal Engine project. Open the project, open Edit > Plugins on the editor menu, enable WhisperRealtime: Whisper-based Real-time Speech Recognition , and restart the project.","title":"Installation"},{"location":"install/#installation","text":"Purchase at UE Marketplace and install it. Create an Unreal Engine project. Open the project, open Edit > Plugins on the editor menu, enable WhisperRealtime: Whisper-based Real-time Speech Recognition , and restart the project.","title":"Installation"},{"location":"modules/","text":"Modules This plugin consists of the following four modules. Module Description Audio Input Spectrum Analysis A module for audio capture and spectrum analysis. This module provides the Mel Log spectrum of microphone input which is then fed to the neutal network. Byte level BPE Tokenizer A module for the conversion between string and \"tokens\". \"Tokens\" are int arrays used for input and output of neural network. Customized Onnx Runtime A module for the execution of the neural network. While UE5 has an experimental Onnx Runtime module in its Neural Network Inference plugin with DirectML acceleration, this module provides the latest version of Onnx Runtime with CUDA acceleration. Whisper Onnx Model A module for the main implementation of speech-to-text feature.","title":"Modules"},{"location":"modules/#modules","text":"This plugin consists of the following four modules. Module Description Audio Input Spectrum Analysis A module for audio capture and spectrum analysis. This module provides the Mel Log spectrum of microphone input which is then fed to the neutal network. Byte level BPE Tokenizer A module for the conversion between string and \"tokens\". \"Tokens\" are int arrays used for input and output of neural network. Customized Onnx Runtime A module for the execution of the neural network. While UE5 has an experimental Onnx Runtime module in its Neural Network Inference plugin with DirectML acceleration, this module provides the latest version of Onnx Runtime with CUDA acceleration. Whisper Onnx Model A module for the main implementation of speech-to-text feature.","title":"Modules"},{"location":"system-requirement/","text":"System Requirements Supported Unreal Engine version: 5.1 Supported Platforms Platform Development Target Build Windows 64bit \u2705 \u2705 Ubuntu Desktop 64bit Android Currently Windows is the only supported platform. But we are willing to add support for Linux and Android in the future. Supported hardware acceleration Platform Default CPU GPU DirectML GPU CUDA GPU TensorRT NNAPI Windows 64bit \u2705 \u2705 Ubuntu Desktop 64bit Android CUDA and cuDNN To use GPU acceleration with CUDA, a supported NVIDIA GPU is required and the following versions of CUDA and cuDNN are required to be installed. Windows CUDA: 11.6 cuDNN: 8.5.0.96","title":"System Requirements"},{"location":"system-requirement/#system-requirements","text":"","title":"System Requirements"},{"location":"system-requirement/#supported-unreal-engine-version","text":"5.1","title":"Supported Unreal Engine version:"},{"location":"system-requirement/#supported-platforms","text":"Platform Development Target Build Windows 64bit \u2705 \u2705 Ubuntu Desktop 64bit Android Currently Windows is the only supported platform. But we are willing to add support for Linux and Android in the future.","title":"Supported Platforms"},{"location":"system-requirement/#supported-hardware-acceleration","text":"Platform Default CPU GPU DirectML GPU CUDA GPU TensorRT NNAPI Windows 64bit \u2705 \u2705 Ubuntu Desktop 64bit Android","title":"Supported hardware acceleration"},{"location":"system-requirement/#cuda-and-cudnn","text":"To use GPU acceleration with CUDA, a supported NVIDIA GPU is required and the following versions of CUDA and cuDNN are required to be installed. Windows CUDA: 11.6 cuDNN: 8.5.0.96","title":"CUDA and cuDNN"}]}