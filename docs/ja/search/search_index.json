{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"What is WhisperRealtime? Whisper-based Real-time Speech Recognition , or WhisperRealtime for short, is an Unreal Engine plugin for real-time speech-to-text transcription and alignment with multi-language support, based on OpenAI's Whisper model. Just add one component to your BP and you are ready to use it. No python or any separated servers needed. Demo project available on GitHub .","title":"What is WhisperRealtime?"},{"location":"#what-is-whisperrealtime","text":"Whisper-based Real-time Speech Recognition , or WhisperRealtime for short, is an Unreal Engine plugin for real-time speech-to-text transcription and alignment with multi-language support, based on OpenAI's Whisper model. Just add one component to your BP and you are ready to use it. No python or any separated servers needed. Demo project available on GitHub .","title":"What is WhisperRealtime?"},{"location":"changelog/","text":"Changelog v1.0 (Dec ??, 2022) First release.","title":"Changelog"},{"location":"changelog/#changelog","text":"","title":"Changelog"},{"location":"changelog/#v10-dec-2022","text":"First release.","title":"v1.0 (Dec ??, 2022)"},{"location":"demo-project-overview/","text":"Realtime transcription demo Download from here System Requirements Windows 10 64bit Microphone connected to your PC If you want to run with GPU, NVIDIA GPU that support CUDA 11.6 CUDA: 11.6 cuDNN: 8.5.0.96 Select microphone Select from the Windows (OS) setting. How to use demo Demo project contains 3 maps which corresponds to the 3 features described in \"How to use\" section. Transcription Alignment for short phrases Alignment for long phrases See these pages for details of the optional settings available in the UI panel on the right side of the window.","title":"Realtime transcription demo"},{"location":"demo-project-overview/#realtime-transcription-demo","text":"Download from here","title":"Realtime transcription demo"},{"location":"demo-project-overview/#system-requirements","text":"Windows 10 64bit Microphone connected to your PC If you want to run with GPU, NVIDIA GPU that support CUDA 11.6 CUDA: 11.6 cuDNN: 8.5.0.96","title":"System Requirements"},{"location":"demo-project-overview/#select-microphone","text":"Select from the Windows (OS) setting.","title":"Select microphone"},{"location":"demo-project-overview/#how-to-use-demo","text":"Demo project contains 3 maps which corresponds to the 3 features described in \"How to use\" section. Transcription Alignment for short phrases Alignment for long phrases See these pages for details of the optional settings available in the UI panel on the right side of the window.","title":"How to use demo"},{"location":"faq/","text":"FAQ UE crashes when GPU_CUDA is selected Please confirm you have installed CUDA and cuDNN correctly. Transcipt result is unstable Please speak loudly near the microphone. Try larger models","title":"FAQ"},{"location":"faq/#faq","text":"","title":"FAQ"},{"location":"faq/#ue-crashes-when-gpu_cuda-is-selected","text":"Please confirm you have installed CUDA and cuDNN correctly.","title":"UE crashes when GPU_CUDA is selected"},{"location":"faq/#transcipt-result-is-unstable","text":"Please speak loudly near the microphone. Try larger models","title":"Transcipt result is unstable"},{"location":"how-to-use-alignment-long/","text":"Alignment for long phrases See Plugins > WhisperRealtime > Sample > BP > Alignment_Long > BP_WhisperAlignmentRealtime for a sample implementation. You can test it in sample map located at Plugins > WhisperRealtime > Sample > Map > test_AlignmentLong . Basic setup Create an actor blueprint. Add Whisper Realtime Alignment Long component. Set the default Neural Net settings: See How to use - Transcription page for the details. Set the default alignment settings: See How to use - Alignment for short phrases page for the details. Set the default alignment settings for long phrases: Specify Min Token Length to Search , number of tokens to check if they have been spoken. Specify Probability Threshold , a confidence threshold base for determining speech. Formula If b is this value and p is the probability of occurrence of each token when silence is input, then (1 - p) * b + p is the final threshold value. Specify Max Skip at Beginning of Speech , number of tokens below the threshold are allowed to be skipped at the start of a speech. Specify Max Skip during Speech , number of tokens below the threshold are allowed to be skipped during a speech. Get results from On Speaking event and On Spoken event. These events provide an array of Alignment Long Result . The elements of the array hold the the following 3 propeties: Spoken history : Substring of the phrase up to the point where it was spoken. Cursor : Index of the first token that is not yet spoken. Probabilities : Probability of each token in the phrase whether or not it was spoken. See How to use - Transcription page for the difference of On Speaking and On Spoken events. Reset the progress Call \"Reset Progress\" function to reset the progress of alignment for all phrases. Change settings To change Alignment settings, call Change Alignment Setting function. To change Phrases to Align , call Set Phrases function. To change Neural Net settings, call Change Neural Net Setting function.","title":"Alignment for long phrases"},{"location":"how-to-use-alignment-long/#alignment-for-long-phrases","text":"See Plugins > WhisperRealtime > Sample > BP > Alignment_Long > BP_WhisperAlignmentRealtime for a sample implementation. You can test it in sample map located at Plugins > WhisperRealtime > Sample > Map > test_AlignmentLong .","title":"Alignment for long phrases"},{"location":"how-to-use-alignment-long/#basic-setup","text":"Create an actor blueprint. Add Whisper Realtime Alignment Long component. Set the default Neural Net settings: See How to use - Transcription page for the details. Set the default alignment settings: See How to use - Alignment for short phrases page for the details. Set the default alignment settings for long phrases: Specify Min Token Length to Search , number of tokens to check if they have been spoken. Specify Probability Threshold , a confidence threshold base for determining speech. Formula If b is this value and p is the probability of occurrence of each token when silence is input, then (1 - p) * b + p is the final threshold value. Specify Max Skip at Beginning of Speech , number of tokens below the threshold are allowed to be skipped at the start of a speech. Specify Max Skip during Speech , number of tokens below the threshold are allowed to be skipped during a speech. Get results from On Speaking event and On Spoken event. These events provide an array of Alignment Long Result . The elements of the array hold the the following 3 propeties: Spoken history : Substring of the phrase up to the point where it was spoken. Cursor : Index of the first token that is not yet spoken. Probabilities : Probability of each token in the phrase whether or not it was spoken. See How to use - Transcription page for the difference of On Speaking and On Spoken events.","title":"Basic setup"},{"location":"how-to-use-alignment-long/#reset-the-progress","text":"Call \"Reset Progress\" function to reset the progress of alignment for all phrases.","title":"Reset the progress"},{"location":"how-to-use-alignment-long/#change-settings","text":"To change Alignment settings, call Change Alignment Setting function. To change Phrases to Align , call Set Phrases function. To change Neural Net settings, call Change Neural Net Setting function.","title":"Change settings"},{"location":"how-to-use-alignment-short/","text":"Alignment for short phrases See Plugins > WhisperRealtime > Sample > BP > Alignment_Short > BP_WhisperAlignmentRealtime for a sample implementation. You can test it in sample map located at Plugins > WhisperRealtime > Sample > Map > test_AlignmentShort . Basic setup Create an actor blueprint. Add Whisper Realtime Alignment Short component. Set the default Neural Net settings: See How to use - Transcription page for the details. Set the default alignment settings: Specify Phrases to Align . Specify Prohibited letters if you want to remove certain letters from the phrases. This is a simple feature just for removing symbols from the phrases. It is recommended that symbols such as \"\" (double quotation) are not included in the phrases, because they are not actually pronounced in the speech. Get results from On Speaking event and On Spoken event. These events provide an array of Alignment Short Result . The elements of the array hold the phrase index and the probability of being spoken. The array is sorted in order of probability of being spoken. See How to use - Transcription page for the difference of On Speaking and On Spoken events. Check thresholds to trigger specific events See Issue Voice Command function of Plugins > WhisperRealtime > Sample > BP > Alignment_Short > BP_WhisperAlignmentRealtime for a sample implementation. This function demonstrates: How to check the probabilities How to avoid the same event being called repeatedly while the user is speaking How to accept the next voice command immediately after one is accepted Change settings To change Phrases to Align , call Set Phrases function. To change Neural Net settings, call Change Neural Net Setting function.","title":"Alignment for short phrases"},{"location":"how-to-use-alignment-short/#alignment-for-short-phrases","text":"See Plugins > WhisperRealtime > Sample > BP > Alignment_Short > BP_WhisperAlignmentRealtime for a sample implementation. You can test it in sample map located at Plugins > WhisperRealtime > Sample > Map > test_AlignmentShort .","title":"Alignment for short phrases"},{"location":"how-to-use-alignment-short/#basic-setup","text":"Create an actor blueprint. Add Whisper Realtime Alignment Short component. Set the default Neural Net settings: See How to use - Transcription page for the details. Set the default alignment settings: Specify Phrases to Align . Specify Prohibited letters if you want to remove certain letters from the phrases. This is a simple feature just for removing symbols from the phrases. It is recommended that symbols such as \"\" (double quotation) are not included in the phrases, because they are not actually pronounced in the speech. Get results from On Speaking event and On Spoken event. These events provide an array of Alignment Short Result . The elements of the array hold the phrase index and the probability of being spoken. The array is sorted in order of probability of being spoken. See How to use - Transcription page for the difference of On Speaking and On Spoken events.","title":"Basic setup"},{"location":"how-to-use-alignment-short/#check-thresholds-to-trigger-specific-events","text":"See Issue Voice Command function of Plugins > WhisperRealtime > Sample > BP > Alignment_Short > BP_WhisperAlignmentRealtime for a sample implementation. This function demonstrates: How to check the probabilities How to avoid the same event being called repeatedly while the user is speaking How to accept the next voice command immediately after one is accepted","title":"Check thresholds to trigger specific events"},{"location":"how-to-use-alignment-short/#change-settings","text":"To change Phrases to Align , call Set Phrases function. To change Neural Net settings, call Change Neural Net Setting function.","title":"Change settings"},{"location":"how-to-use-transcript/","text":"Transcription See Plugins > WhisperRealtime > Sample > BP > Transcript > BP_WhisperTranscriptRealtime for a sample implementation. You can test it in sample map located at Plugins > WhisperRealtime > Sample > Map > test_Transcript . Basic setup Create an actor blueprint. Add Whisper Realtime Transcript component. Set the default Neural Net settings: Specify Model Size . The larger the model, higher the accuracy and the CPU/GPU/memory usage. Specify Execution device , whether to use CPU or GPU. Specify GPU Device ID if you use GPU and you have multiple GPUs in your PC. Specify Language spoken . Specify Do Translate to English . If you just want to transcribe speech to text in the language specified above, leave unchecked. Set the default Audio Input Spectrum Analysis settings: Specify Silence Volume Threshold , volume threshold for determining silence. Maximum microphone input is 1.0. Complete silence is 0.0. Specify Silence Duration Threshold , time threshold for determining silent state (in seconds). If the volume below Silence Volume Threshold continues for this time, a transition is made from the speech state to the silent state. Specify Speaking Duration Threshold , Time threshold for determining speaking state (in seconds). If the volume above Silence Volume Threshold continues for this time, a transition is made from the silent state to the speech state. Set the default transcript settings: Specify Prohibited Phrases if you want to suppress certain phrases. Note that this feature simply removes the specified phrases from the result. If you specify a short phrase, for example at , the phrase will be removed from all words (e.g. that becomes th ). Get results from On Speaking event and On Spoken event. On Speaking event gives intermidiate result while the user is still speaking. On Spoken event gives the final result after the user stops speaking. Note The values for Audio Input Spectrum Analysis settings are used to determine user is speaking or not. Change settings To change Neural Net settings, call Change Neural Net Setting function. Stop and restart To stop transcription or translation, call Stop Mic Input function. To restart transcription or translation, call Restart Mic Input function.","title":"Transcription"},{"location":"how-to-use-transcript/#transcription","text":"See Plugins > WhisperRealtime > Sample > BP > Transcript > BP_WhisperTranscriptRealtime for a sample implementation. You can test it in sample map located at Plugins > WhisperRealtime > Sample > Map > test_Transcript .","title":"Transcription"},{"location":"how-to-use-transcript/#basic-setup","text":"Create an actor blueprint. Add Whisper Realtime Transcript component. Set the default Neural Net settings: Specify Model Size . The larger the model, higher the accuracy and the CPU/GPU/memory usage. Specify Execution device , whether to use CPU or GPU. Specify GPU Device ID if you use GPU and you have multiple GPUs in your PC. Specify Language spoken . Specify Do Translate to English . If you just want to transcribe speech to text in the language specified above, leave unchecked. Set the default Audio Input Spectrum Analysis settings: Specify Silence Volume Threshold , volume threshold for determining silence. Maximum microphone input is 1.0. Complete silence is 0.0. Specify Silence Duration Threshold , time threshold for determining silent state (in seconds). If the volume below Silence Volume Threshold continues for this time, a transition is made from the speech state to the silent state. Specify Speaking Duration Threshold , Time threshold for determining speaking state (in seconds). If the volume above Silence Volume Threshold continues for this time, a transition is made from the silent state to the speech state. Set the default transcript settings: Specify Prohibited Phrases if you want to suppress certain phrases. Note that this feature simply removes the specified phrases from the result. If you specify a short phrase, for example at , the phrase will be removed from all words (e.g. that becomes th ). Get results from On Speaking event and On Spoken event. On Speaking event gives intermidiate result while the user is still speaking. On Spoken event gives the final result after the user stops speaking. Note The values for Audio Input Spectrum Analysis settings are used to determine user is speaking or not.","title":"Basic setup"},{"location":"how-to-use-transcript/#change-settings","text":"To change Neural Net settings, call Change Neural Net Setting function.","title":"Change settings"},{"location":"how-to-use-transcript/#stop-and-restart","text":"To stop transcription or translation, call Stop Mic Input function. To restart transcription or translation, call Restart Mic Input function.","title":"Stop and restart"},{"location":"install/","text":"Installation Purchase at UE Marketplace and install it. Create an Unreal Engine project. Open the project, open Edit > Plugins on the editor menu, enable WhisperRealtime: Whisper-based Real-time Speech Recognition , and restart the project.","title":"Installation"},{"location":"install/#installation","text":"Purchase at UE Marketplace and install it. Create an Unreal Engine project. Open the project, open Edit > Plugins on the editor menu, enable WhisperRealtime: Whisper-based Real-time Speech Recognition , and restart the project.","title":"Installation"},{"location":"modules/","text":"Modules This plugin consists of the following 5 modules. Module Description Audio Input Spectrum Analysis A module for audio capture and spectrum analysis. This module provides the Mel Log spectrum of microphone input which is then fed to the neutal network. Byte level BPE Tokenizer A module for the conversion between string and \"tokens\". \"Tokens\" are int arrays used for input and output of neural network. Customized Onnx Runtime A module for the execution of the neural network. While UE5 has an experimental Onnx Runtime module in its Neural Network Inference plugin with DirectML acceleration, this module provides the latest version of Onnx Runtime with CUDA acceleration. Customized Onnx Runtime Editor A module for defining UAsset of ONNX model. Whisper Onnx Model A module for the main implementation of speech-to-text feature.","title":"Modules"},{"location":"modules/#modules","text":"This plugin consists of the following 5 modules. Module Description Audio Input Spectrum Analysis A module for audio capture and spectrum analysis. This module provides the Mel Log spectrum of microphone input which is then fed to the neutal network. Byte level BPE Tokenizer A module for the conversion between string and \"tokens\". \"Tokens\" are int arrays used for input and output of neural network. Customized Onnx Runtime A module for the execution of the neural network. While UE5 has an experimental Onnx Runtime module in its Neural Network Inference plugin with DirectML acceleration, this module provides the latest version of Onnx Runtime with CUDA acceleration. Customized Onnx Runtime Editor A module for defining UAsset of ONNX model. Whisper Onnx Model A module for the main implementation of speech-to-text feature.","title":"Modules"},{"location":"system-requirement/","text":"System Requirements Supported Unreal Engine version: 5.1 Supported Platforms Platform Development Target Build Windows 64bit \u2705 \u2705 Ubuntu Desktop 64bit Android Currently Windows is the only supported platform. But we are willing to add support for Linux and Android in the future. Supported hardware acceleration Platform Default CPU GPU DirectML GPU CUDA GPU TensorRT NNAPI Windows 64bit \u2705 \u2705 Ubuntu Desktop 64bit Android CUDA and cuDNN To use GPU acceleration with CUDA, a supported NVIDIA GPU is required and the following versions of CUDA and cuDNN are required to be installed. Windows CUDA: 11.6 cuDNN: 8.5.0.96","title":"System Requirements"},{"location":"system-requirement/#system-requirements","text":"","title":"System Requirements"},{"location":"system-requirement/#supported-unreal-engine-version","text":"5.1","title":"Supported Unreal Engine version:"},{"location":"system-requirement/#supported-platforms","text":"Platform Development Target Build Windows 64bit \u2705 \u2705 Ubuntu Desktop 64bit Android Currently Windows is the only supported platform. But we are willing to add support for Linux and Android in the future.","title":"Supported Platforms"},{"location":"system-requirement/#supported-hardware-acceleration","text":"Platform Default CPU GPU DirectML GPU CUDA GPU TensorRT NNAPI Windows 64bit \u2705 \u2705 Ubuntu Desktop 64bit Android","title":"Supported hardware acceleration"},{"location":"system-requirement/#cuda-and-cudnn","text":"To use GPU acceleration with CUDA, a supported NVIDIA GPU is required and the following versions of CUDA and cuDNN are required to be installed. Windows CUDA: 11.6 cuDNN: 8.5.0.96","title":"CUDA and cuDNN"}]}